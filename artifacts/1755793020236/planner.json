{
  "production_checklist": [
    "Script (1.5–3 hr): Draft a tight script with timestamps: 00:00–00:15 hook (explicit value), 00:15–00:45 preview/promise, 00:45–main content broken into 3–5 segments, last 30s recap+CTA. Quality checkpoint: read-aloud rehearsal — confirm hook delivers a specific, measurable promise (e.g., \"build a RAG agent that answers docs with <1% hallucinations\") and preview within 15s.",
    "Prep & assets (30–60 min): Prepare runnable repo link, code snippets, diagrams, and slides. Quality checkpoint: validate code runs end-to-end locally and include short demo dataset so viewers can follow along in <10 min.",
    "Record (30–90 min): Record high-quality audio (>=44.1kHz) and 1080p+ video or screen capture. Chunk into segments per script section to allow re-takes. Quality checkpoints: audio noise gate check, mic distance, camera framing, verify screen text is legible at target resolution, and record a 15s cold open take that matches script promise.",
    "Edit (3–6 hr): Tighten pace to maintain retention (cut dead-air, trim pauses to <200–300ms, remove filler words). Add on-screen highlights for code and key takeaways, visual jump-cuts every 30–90s, and a recurring 2–3 minute engagement hook (\"but here's the crazy part...\"). Quality checkpoints: first-pass runtime within target length, captions synced, 2 viewers QA test for clarity and pacing, retention-focused rough cut with markers where viewers may drop.",
    "Thumbnail & Chapters (1–2 hr): Create 2–3 thumbnail variants (bold headline, emotion, and visual of demo/results) and prepare timestamped chapters using pillar keywords (e.g., \"00:45 — Vector DB setup (FAISS)\"). Quality checkpoints: A/B test thumbnails internally or via small ad set; confirm chapters include primary keywords and align to content beats.",
    "Upload & SEO (30–60 min): Upload with optimized title (primary long-tail keyword in first 60 characters), first sentence of description repeating that keyword verbatim, 3–5 close keyword tags, full transcript/closed captions, and pinned comment with repo link + keyword-rich summary. Quality checkpoints: run keyword density check (~1.0–1.8% target), ensure captions auto-synced and links open correctly.",
    "Publish & Monitoring (ongoing): Share pinned comment with calls-to-action, schedule community post and 1st-hour engagement plan (reply to top 5 comments). Quality checkpoints: monitor first 24–72 hrs retention graph, click-through rate (CTR) for thumbnail, and iterate on title/thumbnail if CTR < 4% or average view duration < target."
  ],
  "hook_outline": [
    "Live demo curiosity + promise (0–15s): \"In the next 10 minutes I'll build a RAG agent that answers from your docs without hallucinations — and I’ll push the exact repo so you can run it now.\" Curiosity gap: how can it be production-safe so fast? Promise: runnable code and measurable accuracy.",
    "Cost/optimization tease (0–15s): \"I cut our RAG costs by 70% with three micro-optimizations — the third one will surprise you and saves latency too.\" Curiosity gap: what is the counterintuitive third tweak? Promise: exact config changes and numbers.",
    "Accuracy vs latency shocker (0–15s): \"This RAG stack answers enterprise queries with 99% precision and 5x lower latency — watch me connect LangChain + FAISS and benchmark live.\" Curiosity gap: how both high accuracy and low latency are achieved. Promise: step-by-step wiring and live benchmarks.",
    "Failure-to-fix quick win (0–15s): \"If your RAG agent hallucinates or returns wrong docs, do these three fixes now — I’ll reproduce the bug and show the fix in under 3 minutes.\" Curiosity gap: what common mistake causes hallucinations? Promise: reproducible bug + immediate fix.",
    "Security/compliance hook (0–15s): \"Deploy a GDPR-safe RAG pipeline in under 15 minutes — I’ll show PII filtering, encryption, and index redaction so legal can sleep at night.\" Curiosity gap: how to be both fast and compliant. Promise: concrete config and checklist."
  ],
  "title_style_notes": [
    "Include the primary long-tail keyword within the first 60 characters (e.g., \"Build RAG Agent from Scratch — LangChain + FAISS Tutorial\") and repeat the exact phrase in the first sentence of the description (SEO rule from research data).",
    "Use emotional triggers and power words: lead with verbs or outcomes (Build, Stop, Fix, Optimize), and add power modifiers (Quick, Production-Ready, 99% Accurate, 70% Cost Cut). Example formula: [Action] + [Primary Keyword] + — [Big Outcome/Metric].",
    "A/B test 2–3 variants for 48–72 hours: (A) Technical straight: \"RAG Agent Tutorial: LangChain + FAISS (Step-by-Step)\" vs (B) Outcome-driven: \"Build a RAG Agent That Stops Hallucinations — 99% Accurate Demo\". Track CTR and average view duration; iterate title if CTR is below channel baseline.",
    "Include urgency or specificity when relevant (time, metric, or dataset): e.g., \"in 10 minutes\", \"for enterprise search\", \"with 5k docs\". These concrete cues increase click intent from technical audience."
  ],
  "content_structure": [
    "00:00–00:15 Hook (problem/promise) — 15s: Deliver a tight curiosity gap + explicit value (e.g., \"I’ll build a production RAG agent that serves enterprise docs with <1% hallucination — runnable repo included\"). Retention note: aim for <3s to state the exact deliverable.",
    "00:15–00:45 Context/setup (why this matters & preview) — 30s: Explain target audience, show final demo output, and give a 10–20s preview of the repo/demo results. Retention note: this is the fulfillment of the hook promise — show evidence quickly to reduce drop-offs at 30–60s.",
    "00:45–04:00 Segment 1 — Data & Embeddings (3:15): Ingest pipeline, filtering, PII handling, and embedding strategy (choice of model + dimension). Add an engagement hook at ~02:30: \"But there's a tradeoff here — and most people pick wrong — here's why.\" Retention curve tactic: include on-screen checklist and short runnable snippet.",
    "04:00–08:00 Segment 2 — Vector DB & Retriever (4:00): FAISS vs Pinecone tradeoffs, indexing patterns, chunking heuristics, and recall tuning. Add micro-demo showing a bad vs tuned retriever. Insert engagement cue at ~06:00: \"Want the exact config file? Drop a comment and I’ll pin it.\"",
    "08:00–12:00 Segment 3 — Agent Wiring & Prompting (4:00): LangChain orchestration, prompt templates for retrieval-aware answers, tool chaining, and fallback logic to reduce hallucination. Mid-section engagement hook: demo a hallucination and then apply the fix — \"here's the crazy part\" moment.",
    "12:00–14:30 Segment 4 — Deployment & Optimization (2:30): Latency profiling, batching, caching, cost tweaks (the 3 optimizations from hook), autoscaling notes. Retention tactic: show benchmark charts and a 1-line switch that yields 5x improvement.",
    "14:30–15:30 Testing, Monitoring & Security (1:00): Evaluation metrics to track (EM/F1/recall), logging, and GDPR/PII index redaction checklist. Keep this tight — reference a repo test-suite for details.",
    "15:30–16:00 Recap + CTA + Next Video Tease (Last 30s): Rapid recap of 3–5 TL;DR bullets, explicit CTA to star/clone the repo in pinned comment, ask one focused question for comments (e.g., \"Which dataset should I benchmark next: legal or support logs?\"), and tease next video (e.g., \"Next: low-cost AWS deployment and autoscaling demo\")."
  ],
  "engagement_tactics": [
    "Pinned comment + Repo CTA: Pin a comment with the runnable repo, one-line setup commands, and a single question prompting viewers to reply (e.g., \"Which dataset should I benchmark next?\"), increasing early engagement and comment-driven reach.",
    "Mid-video interactive CTA & chapter jump: At 30–60s and every 2–3 minutes say a short engagement hook (\"If you want the exact config file, tap the chapter 'Vector DB setup' below\") and add clickable timestamped chapters so viewers can jump to code or benchmark — this increases session time and rewatch.",
    "Clear micro-CTAs tied to value: instead of generic \"like and subscribe\", use task CTAs that increase watch time: \"Try this snippet in the repo and comment the output you get—I'll pin the best reproduction.\" This drives hands-on engagement and multiple views.",
    "End-screen & next-video tease aligned to viewer intent: End with a strong CTA to a specific follow-up video (e.g., \"Autoscale RAG on AWS — benchmark next\") and use a custom end-screen element placed at 10–20s before the end so YouTube can recommend the next relevant clip and increase session watch time.",
    "Community poll + pinned follow-up resources: Within 24 hours publish a community poll (which deployment/model to test next) and update pinned comment with timestamps, cheat-sheet, and a short FAQ to capture viewers who rewatch for the code — this both boosts comment velocity and retention on replays."
  ]
}